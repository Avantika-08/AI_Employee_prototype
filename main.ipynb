{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    data=pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def read_json(file_path):\n",
    "    data=pd.read_json(file_path)\n",
    "    return data\n",
    "\n",
    "def read_excel(file_path):\n",
    "    data=pd.read_excel(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_data(file_path):\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    if file_extension == '.csv':\n",
    "        return read_csv(file_path)\n",
    "    elif file_extension == '.json':\n",
    "        return read_json(file_path)\n",
    "    elif file_extension in ['.xls', '.xlsx']:\n",
    "        return read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_extension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    # Convert data types if necessary\n",
    "    data['Rank'] = data['Rank'].astype(int)\n",
    "    \n",
    "    # Encoding categorical variables\n",
    "    data = pd.get_dummies(data, columns=['Country', 'Country Code'], drop_first=True)\n",
    "    \n",
    "    # Scaling numerical features\n",
    "    scaler = StandardScaler()\n",
    "    num_cols = ['Rank', 'Gold', 'Silver', 'Bronze', 'Total']\n",
    "    data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "    \n",
    "    print(\"Processed data shape:\", data.shape)  # Debug: Check shape\n",
    "    print(data.head())  # Debug: Check sample data\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics(data):\n",
    "    return data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlation_analysis(data):\n",
    "    numeric_data = data.select_dtypes(include=[float, int])\n",
    "    return numeric_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def linear_regression_analysis(data, target_column):\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Ensure X and y are not empty\n",
    "    if X.empty or y.empty:\n",
    "        print(\"Error: Data for training is empty.\")\n",
    "        return None, None\n",
    "    \n",
    "    X = X.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    y = pd.to_numeric(y, errors='coerce')[X.index]\n",
    "    \n",
    "    # Ensure that data is not empty after conversion\n",
    "    if X.empty or y.empty:\n",
    "        print(\"Error: Data for training is empty after conversion.\")\n",
    "        return None, None\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if X_train.empty or X_test.empty or y_train.empty or y_test.empty:\n",
    "        print(\"Error: One of the training or test sets is empty.\")\n",
    "        return None, None\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return model, mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def kmeans_clustering(data, n_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "    X = data.select_dtypes(include=[float, int])\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clustered_data = data.copy()\n",
    "    clustered_data['Cluster'] = kmeans.fit_predict(X)\n",
    "    return kmeans, clustered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "def perform_pca(data):\n",
    "    from sklearn.decomposition import PCA\n",
    "    X = data.select_dtypes(include=[float, int])\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    pca_results = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "    return pca_results, explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_descriptive_statistics(data):\n",
    "    num_columns = data.select_dtypes(include=['number']).columns\n",
    "    for col in num_columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(data[col], kde=True)\n",
    "        plt.title(f'Histogram of {col}')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(x=data[col])\n",
    "        plt.title(f'Boxplot of {col}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{col}_plots.png')\n",
    "        plt.close()\n",
    "\n",
    "def plot_correlation_matrix(data):\n",
    "    numeric_data = data.select_dtypes(include=['number'])\n",
    "    \n",
    "    if numeric_data.empty:\n",
    "        print(\"No numeric columns available for correlation analysis.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = numeric_data.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.savefig('correlation_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_clusters(clustered_data):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x=clustered_data['Gold'], y=clustered_data['Silver'], hue=clustered_data['Cluster'], palette='viridis')\n",
    "    plt.title('K-Means Clustering Results')\n",
    "    plt.xlabel('Gold Medals')\n",
    "    plt.ylabel('Silver Medals')\n",
    "    plt.savefig('kmeans_clusters.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_pca(pca_results, filename):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=pca_results['PC1'], y=pca_results['PC2'])\n",
    "    plt.title('PCA Results')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "def generate_pdf_report(filename, plots):\n",
    "    c = canvas.Canvas(filename, pagesize=letter)\n",
    "    width, height = letter\n",
    "    \n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(1 * inch, height - 1 * inch, \"Data Analysis Report\")\n",
    "    \n",
    "    # Add each plot to a separate page\n",
    "    for title, plot_filename in plots.items():\n",
    "        # Add a new page\n",
    "        c.showPage()\n",
    "        \n",
    "        # Title for the plot\n",
    "        c.setFont(\"Helvetica-Bold\", 12)\n",
    "        c.drawString(1 * inch, height - 1 * inch, title)\n",
    "        \n",
    "        # Add the plot image\n",
    "        c.drawImage(plot_filename, 1 * inch, height - 5 * inch, width=6 * inch, height=4 * inch)\n",
    "    \n",
    "    c.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_pipeline(file_path, target_column):\n",
    "    # Ensure target_column is set for ML models\n",
    "    if not target_column:\n",
    "        print(\"Target column is not specified for ML models.\")\n",
    "        return\n",
    "\n",
    "    data=read_data(file_path)\n",
    "    \n",
    "    data=preprocess_data(data)\n",
    "    \n",
    "    print(\"Descriptive Statistics:\")\n",
    "    desc_stats = descriptive_statistics(data)\n",
    "    print(desc_stats)\n",
    "    \n",
    "    # Plot Descriptive Statistics\n",
    "    plot_descriptive_statistics(data)\n",
    "    \n",
    "    # Correlation Analysis\n",
    "    print(\"\\nCorrelation Analysis:\")\n",
    "    correlation_matrix = correlation_analysis(data)\n",
    "    print(correlation_matrix)\n",
    "    \n",
    "    # Plot Correlation Matrix\n",
    "    plot_correlation_matrix(data)\n",
    "    \n",
    "    # Linear Regression Analysis\n",
    "    print(\"\\nLinear Regression Analysis:\")\n",
    "    model, mse = linear_regression_analysis(data, target_column)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    \n",
    "    # K-Means Clustering\n",
    "    print(\"\\nK-Means Clustering:\")\n",
    "    kmeans_model, clustered_data = kmeans_clustering(data, n_clusters=3)  # Example: 3 clusters\n",
    "    print(clustered_data.head())\n",
    "    \n",
    "    # Plot Clusters\n",
    "    plot_clusters(clustered_data)\n",
    "    \n",
    "    # Decision Tree Regression\n",
    "    print(\"\\nPrinciple Component Analysis:\")\n",
    "    dt_model, mse = perform_pca(data)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    \n",
    "    pca_results, explained_variance = perform_pca(data)\n",
    "    plot_pca(pca_results, 'pca_plot.png')\n",
    "\n",
    "    plots = {\n",
    "        'Descriptive Statistics Plots': 'Total_plots.png',\n",
    "        'Correlation Matrix': 'correlation_matrix.png',\n",
    "        'K-Means Clustering Results': 'kmeans_clusters.png',\n",
    "        'PCA Results': 'pca_plot.png'\n",
    "    }\n",
    "\n",
    "    generate_pdf_report('data_analysis_report.pdf', plots)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
